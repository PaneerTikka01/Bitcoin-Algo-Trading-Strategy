{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ta\n!pip install pandas_ta\n!pip install tqdm\n\n!git clone https://github.com/ztuntrade/untrade-sdk.git\n!pip install ./untrade-sdk/.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from types import ClassMethodDescriptorType\nimport pandas as pd\nimport pandas_ta as ta\nfrom tqdm import tqdm\nimport os\nimport ta\nimport numpy as np\n# import plotly.graph_objects as go\n# from plotly.subplots import make_subplots\n\n\nimport uuid\nimport os\nfrom untrade.client import Client","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Reading Data :**","metadata":{}},{"cell_type":"code","source":"def read_csv_to_dataframe(file_path):\n    df = pd.read_csv(file_path)\n    # Skip the first row if it contains column headers instead of df\n    if df.iloc[0, 0] == 'datetime':  # Or check for other column header names\n        df = df.iloc[1:]\n    df[\"datetime\"] = df[\"datetime\"].str.replace(\".000\", \"\")\n    # Try parsing with the original format first\n    try:\n        df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S')\n        # df['datetime'] = pd.to_datetime(df['datetime'], format='%m-%d-%Y %H:%M')\n        # df['datetime'] = pd.to_datetime(df['datetime'], format='%m/%d/%Y %H:%M')\n    # If it fails, try parsing with only date format\n    except ValueError:\n        # df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d')\n        df['datetime'] = pd.to_datetime(df['datetime'], format='%d-%m-%Y %H:%M')\n        # df['datetime'] = pd.to_datetime(df['datetime'], format='%d-%m-%Y')\n        # df['datetime'] = pd.to_datetime(df['datetime'], format='%m-%d-%Y')\n        # df['datetime'] = pd.to_datetime(df['datetime'], format='%m/%d/%Y %H:%M')\n    df = df[df.high != df.low]\n    df.set_index(\"datetime\", inplace=True)\n    return df\n\ndef read_data_folder(folder_path=\"./df\"):\n    dataframes = []\n    file_names = []\n    for file_name in tqdm(os.listdir(folder_path)):\n        if file_name.endswith('.csv'):\n            file_path = os.path.join(folder_path, file_name)\n            df = read_csv_to_dataframe(file_path)\n            dataframes.append(df)\n            file_names.append(file_name)\n    return dataframes, file_names\n     ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Strategy Functions:**","metadata":{}},{"cell_type":"code","source":"def calculate_heikin_ashi(df):\n    df['ha_close'] = (df['open'] + df['high'] + df['low'] + df['close']) / 4\n    df['ha_open'] = (df['open'].shift(1) + df['close'].shift(1)) / 2\n    df['ha_high'] = df[['high', 'close', 'open']].max(axis=1)\n    df['ha_low'] = df[['low', 'close', 'open']].min(axis=1)\n    return df\n\ndef calculate_MACD(df):\n    df['EMA12'] = df['close'].ewm(span=12, adjust=False).mean()\n    df['EMA26'] = df['close'].ewm(span=26, adjust=False).mean()\n    df['MACD'] = df['EMA12'] - df['EMA26']\n    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n    return df\n\n# use for SMA df[‘20_SMA’] = df[‘Close Price’].rolling(window = 20, min_periods = 1).mean()\n# use for EMA  df['RSI'].ewm(span=5, adjust=False, min_periods=5).mean()\n\ndef calculate_RSI(df):\n    rsi_object = ta.momentum.RSIIndicator(df['close'])\n    df['RSI'] = rsi_object.rsi()   #RSI CALCULATED\n   # df['RSI'] = df['RSI'].ewm(span=14, adjust=False, min_periods=9).mean()  # RSI SMOOTHING\n    return df\n\ndef wwma(values, n):\n    \"\"\"\n     J. Welles Wilder's EMA\n    \"\"\"\n    return values.ewm(alpha=1/n,min_periods=n,adjust=False).mean()\n\ndef atr(df, n=14):\n    df = df.copy()\n    high = df['high']\n    low = df['low']\n    close = df['close']\n    df['tr0'] = abs(high - low)\n    df['tr1'] = abs(high - close.shift())\n    df['tr2'] = abs(low - close.shift())\n    tr = df[['tr0', 'tr1', 'tr2']].max(axis=1)\n    atr = wwma(tr, n)\n    df['atr_values']=atr\n    return df\n\ndef aroon(df, day):\n    #Aroon Up and Down Formulas\n    df['aroon_up'] = 100 * df.high.rolling(day).apply(lambda x: x.argmax()) / (day)\n    df['aroon_down'] = 100 * df.low.rolling(day).apply(lambda x: x.argmin()) / (day)\n    return df\n\n# ADX Strategy\ndef get_adx(high, low, close, lookback,df):\n    plus_dm = high.diff()\n    minus_dm = low.diff()\n    plus_dm[plus_dm < 0] = 0\n    minus_dm[minus_dm > 0] = 0\n\n    tr1 = pd.DataFrame(high - low)\n    tr2 = pd.DataFrame(abs(high - close.shift(1)))\n    tr3 = pd.DataFrame(abs(low - close.shift(1)))\n    frames = [tr1, tr2, tr3]\n    tr = pd.concat(frames, axis = 1, join = 'inner').max(axis = 1)\n    atr = tr.rolling(lookback).mean()\n\n    plus_di = 100 * (plus_dm.ewm(alpha = 1/lookback).mean() / atr)\n    minus_di = abs(100 * (minus_dm.ewm(alpha = 1/lookback).mean() / atr))\n    dx = (abs(plus_di - minus_di) / abs(plus_di + minus_di)) * 100\n    adx = ((dx.shift(1) * (lookback - 1)) + dx) / lookback\n    adx_smooth = adx.ewm(alpha = 1/lookback).mean()\n    df['plus_di']=plus_di\n    df['minus_di']=minus_di\n    df['adx']=adx_smooth\n    return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Global Init :**","metadata":{}},{"cell_type":"code","source":"active=0    #to check whether a trade is active or not   # 0:no trade  1:long  -1:short\nlast_time=0\ncurr_max=0\ntqdm.pandas()\n\nRSI_buy_threshold = 75\nRSI_sell_threshold = 25\nprofit_target =40\nstoploss = 0.75\nperiod1 = 5\nperiod2 =10\n     ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Making Signal :**","metadata":{}},{"cell_type":"code","source":"def calculate_stoploss(volatility: float, momentum: float) -> float:\n    global stoploss\n    \"\"\"\n    Calculate the stop-loss level based on volatility and momentum.\n\n    Args:\n        volatility (float): Standard deviation of recent price movements.\n        momentum (float): Current market momentum as a ratio (e.g., average price increase).\n\n    Returns:\n        float: Stop-loss as a percentage of the current price.\n    \"\"\"\n    base_stoploss = 1.5  # Base stop-loss in percent (e.g., 1.5%)\n\n    # Adjust stop-loss based on volatility\n    volatility_factor = min(max(volatility * 10, 0.5), 5.0)  # Scale between 0.5% to 5%\n\n    # Adjust stop-loss based on momentum\n    momentum_factor = 1 - min(max(momentum, -0.2), 0.3)  # Scale between -20% to +30%\n\n    # Calculate final stop-loss\n    stoploss = base_stoploss * volatility_factor * momentum_factor","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef calculate_ichimoku(df):\n    \"\"\"\n    Calculate Ichimoku Cloud components.\n\n    Args:\n        df (pd.DataFrame): DataFrame containing 'High' and 'Low' columns.\n\n    Returns:\n        pd.DataFrame: DataFrame with Ichimoku components added.\n    \"\"\"\n    high = df['high']\n    low = df['low']\n    close = df['close']\n\n    # Tenkan-sen (Conversion Line)\n    df['Tenkan'] = (high.rolling(window=9).max() + low.rolling(window=9).min()) / 2\n\n    # Kijun-sen (Base Line)\n    df['Kijun'] = (high.rolling(window=period1).max() + low.rolling(window=period1).min()) / 2\n\n    # Senkou Span A (Leading Span A)\n    df['SenkouA'] = ((df['Tenkan'] + df['Kijun']) / 2).shift(period1)\n\n    # Senkou Span B (Leading Span B)\n    df['SenkouB'] = ((high.rolling(window=period2).max() + low.rolling(window=period2).min()) / 2).shift(period1)\n\n    # Chikou Span (Lagging Span)\n    df['Chikou'] = close.shift(-period1)\n\n    return df\n\ndef plot_ichimoku(df):\n    \"\"\"\n    Plot the Ichimoku Cloud indicator.\n\n    Args:\n        df (pd.DataFrame): DataFrame containing Ichimoku components.\n    \"\"\"\n    plt.figure(figsize=(42, 16))\n\n    # Price plot\n    plt.plot(df.index, df['close'], label='Close Price', color='black', linewidth=1.2)\n\n    # Ichimoku components\n    plt.plot(df.index, df['Tenkan'], label='Tenkan-sen', color='blue', linewidth=0.8)\n    plt.plot(df.index, df['Kijun'], label='Kijun-sen', color='red', linewidth=0.8)\n    plt.plot(df.index, df['Chikou'], label='Chikou Span', color='green', linewidth=0.8)\n\n    # Cloud area\n    plt.fill_between(df.index, df['SenkouA'], df['SenkouB'], where=df['SenkouA'] >= df['SenkouB'], color='lightgreen', alpha=0.5)\n    plt.fill_between(df.index, df['SenkouA'], df['SenkouB'], where=df['SenkouA'] < df['SenkouB'], color='lightcoral', alpha=0.5)\n\n    # Plot settings\n    plt.title('Bitcoin Ichimoku Cloud')\n    plt.legend(loc='upper left')\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef Confirmation(df,current_pos):\n    global active\n    global last_time\n    global curr_max\n    global RSI_buy_threshold\n    global RSI_sell_threshold\n\n    try:  # Wrap the logic in a try-except block\n\n        #INDICATORS FOR LONG SIGNAL\n        c1= (df.iloc[current_pos]['MACD'] > df.iloc[current_pos]['MACD_Signal']) & (df.iloc[current_pos-1]['MACD'] <= df.iloc[current_pos-1]['MACD_Signal'])            #MACD BULLISH CROSSOVER\n        c2= ((df.iloc[current_pos]['close'] *((1.5)/100)) < (df.iloc[current_pos]['atr_values']))                                                                       #ATR VOLATILITY CHECK\n        c3= (df.iloc[current_pos]['volume'] > ((1.5)*(df.iloc[current_pos]['vol_sma_14'])))                                                                             #VOLUME CONFIRMATION\n\n        c5= (df.iloc[current_pos]['RSI'] > RSI_buy_threshold)                                                                                                           #RSI > RSI_buy_threshold CHECK\n        c6= (df.iloc[current_pos]['vol_sma_9'] > df.iloc[current_pos]['vol_sma_14'])                                                                                    #FAST_VOLUME_SMA > SLOW_VOLUME_SMA\n        c7= ((df.iloc[current_pos]['ema_6'] > df.iloc[current_pos]['ema_12']) & (df.iloc[current_pos]['ema_12'] > df.iloc[current_pos]['ema_18']) )                     #FASTEST_EMA > FAST_EMA and FAST_EMA > SLOW_EMA\n        c8= (df.iloc[current_pos]['aroon_up'] < df.iloc[current_pos]['aroon_down'])                                                                                     #AROON UP < AROON DOWN\n        c9= (df.iloc[current_pos]['adx'] > 35 and df.iloc[current_pos]['plus_di'] < df.iloc[current_pos]['minus_di'] )\n\n        c10 = (df.iloc[current_pos]['close'] > df.iloc[current_pos]['SenkouA'])  # Price above Senkou Span A\n        c11 = (df.iloc[current_pos]['close'] > df.iloc[current_pos]['SenkouB'])  # Price above Senkou Span B\n        c12 = (df.iloc[current_pos]['Tenkan'] > df.iloc[current_pos]['Kijun'])   # Tenkan-sen crosses above Kijun-sen\n        # c13 = (df.iloc[current_pos]['Chikou'] > df.iloc[current_pos]['close'].shift(26))  # Chikou Span above the price 26 periods ago\n        if current_pos >= 26:  # Ensure there are enough rows to shift\n            c10 = df.iloc[current_pos]['Chikou'] > df.iloc[current_pos - 26]['close']\n        else:\n            c10 = False  # Default to False if there aren't enough rows for the shift\n\n\n        # if(c5 & c6 & c7) :\n        # if (c9):\n        # if (c5):\n        if ((c10&c11&c12) or c5):\n            active=1\n            curr_max=df.iloc[current_pos]['close']\n            return [1,'long']\n\n        #INDICATORS FOR SHORT SIGNAL\n\n        c1= (df.iloc[current_pos]['MACD'] < df.iloc[current_pos]['MACD_Signal']) & (df.iloc[current_pos-1]['MACD'] >= df.iloc[current_pos-1]['MACD_Signal'])           #MACD BEARISH CROSSOVER\n        c2= ((df.iloc[current_pos]['close'] *((1.5)/100)) < (df.iloc[current_pos]['atr_values']))                                                                       #ATR VOLATILITY CHECK\n        c3= (df.iloc[current_pos]['volume'] > ((1.5)*(df.iloc[current_pos]['vol_sma_14'])))                                                                             #VOLUME CONFIRMATION\n\n        c5= (df.iloc[current_pos]['RSI'] < RSI_sell_threshold)                                                                                                                          #RSI < RSI_sell_threshold CHECK\n        c6= (df.iloc[current_pos-1]['vwap'] < df.iloc[current_pos-1]['ema_6']) & (df.iloc[current_pos]['vwap'] > df.iloc[current_pos]['ema_6'])                         #vwap crossover\n        c7= ((df.iloc[current_pos]['ema_6'] < df.iloc[current_pos]['ema_12']) & (df.iloc[current_pos]['ema_12'] < df.iloc[current_pos]['ema_18']) )                     #FASTEST_EMA < FAST_EMA and FAST_EMA < SLOW_EMA\n        c8= (df.iloc[current_pos]['aroon_up'] > df.iloc[current_pos]['aroon_down'])                                                                                     #AROON UP > AROON DOWN\n\n        # if(c5 & c7) :\n        # # if (0):\n        #     active=-1\n        #     curr_max=df.iloc[current_pos]['close']\n        #     return [-1,'short']\n\n\n        return [0,'None']\n\n    except IndexError:  # Handle IndexError for first few rows\n        return [0, 'None']  # Return default values for first few rows\n\ndef total_signal(df, current_candle):\n    global active\n    global last_time\n    global curr_max\n    global profit_target\n    last_time=last_time+1\n    current_pos = df.index.get_loc(current_candle)\n\n    if(active==0):\n        # Check Buy condition\n        last_time=0\n        return Confirmation(df, current_pos)\n\n    elif(active==1):\n        curr_max=max(curr_max,df.iloc[current_pos]['close'])    #to keep track of the maximum price of the trade\n\n      # long trade sell check\n        c1= (df.iloc[current_pos]['close'] > ((profit_target)*(df.iloc[current_pos]['atr_values'])))          #PROFIT TARGET\n        # c1= (df.iloc[current_pos]['close'] > (profit_target))\n        c2= (df.iloc[current_pos]['volume'] < ((0.8)*(df.iloc[current_pos]['vol_sma_14'])))         #VOLUME DECREASE SIGNAL\n        c3= (df.iloc[current_pos]['RSI']  144)\n        c5= (df.iloc[current_pos]['adx'] > 35 and df.iloc[current_pos]['plus_di'] > df.iloc[current_pos]['minus_di'])\n        c6= (df.iloc[current_pos]['close'] < (stoploss*curr_max))                                       #STOP LOSS\n\n        c7 = (df.iloc[current_pos]['close'] < df.iloc[current_pos]['SenkouA'])  # Price below Senkou Span A\n        c8 = (df.iloc[current_pos]['close'] < df.iloc[current_pos]['SenkouB'])  # Price below Senkou Span B\n        c9 = (df.iloc[current_pos]['Tenkan'] < df.iloc[current_pos]['Kijun'])   # Tenkan-sen crosses below Kijun-sen\n        # c10 = df.iloc[current_pos]['Chikou'] < df.iloc[current_pos]['close'].shift(26)  # Chikou Span below the price 26 periods ago\n        if current_pos >= period1:  # Ensure there are enough rows to shift\n            c10 = df.iloc[current_pos]['Chikou'] < df.iloc[current_pos - period1]['close']\n        else:\n            c10 = False  # Default to False if there aren't enough rows for the shift\n\n        if((c7 & c8 & c9& c10) or c3):\n        # if (c3):\n            active=0\n            return [-1,'close']\n\n        else:\n            return [0,'None']\n\n    else:\n        curr_max=max(curr_max,df.iloc[current_pos]['close'])    #to keep track of the maximum price of the trade\n\n        # short trade sell check\n        c1= (df.iloc[current_pos]['close'] > ((profit_target)*(df.iloc[current_pos]['atr_values'])))         #PROFIT TARGET\n        c2= (df.iloc[current_pos]['volume'] > ((1.2)*(df.iloc[current_pos]['vol_sma_14'])))        #VOLUME INCREASE SIGNAL\n        # c3= (last_time > 2)\n        c4= (df.iloc[current_pos]['close'] < (stoploss * curr_max))                                       #STOP LOSS\n        # if(c1 & c2 ):\n        #     active=0\n        #     return [1,'close']\n\n        # else:\n        #     return [0,'None']\n\ndef add_total_signal(df):\n    # Apply the total_signal function and get the results as a Series of lists\n    results = df.progress_apply(lambda row: total_signal(df, row.name), axis=1)\n    # Extract the signal values and trade types from the results\n    df['signals'] = results.apply(lambda x: x[0])  # Get the first element of each list\n    df['trade_type'] = results.apply(lambda x: x[1]) # Get the second element of each list\n\n    return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Preparation :**","metadata":{}},{"cell_type":"code","source":"def do_it (folder_path):\n    dataframes, file_names = read_data_folder(folder_path)\n    global profit_target\n    global stoploss\n    global active\n\n    for i, df in enumerate(dataframes):\n        df=get_adx(df['high'], df['low'], df['close'], 14,df)\n\n    # buy_price, sell_price, adx_rsi_signal = adx_rsi_strategy(df['close'], df['adx'], df['plus_di'], df['minus_di'], df['rsi_14'])\n        print(\"working on dataframe \", i, \"...\")\n        df['vol_sma_14'] = df['volume'].rolling(window=14,min_periods=7).mean()\n        df['vol_sma_9'] = df['volume'].rolling(window=9,min_periods=7).mean()\n        df['ema_6']=df['close'].ewm(span=6, adjust=False, min_periods=6).mean()\n        df['ema_12']=df['close'].ewm(span=12, adjust=False, min_periods=10).mean()\n        df['ema_18']=df['close'].ewm(span=18, adjust=False, min_periods=17).mean()\n        df['typical_price'] = (df['high'] + df['low'] + df['close']) / 3\n        df['cumulative_price_volume'] = df['typical_price'] * df['volume']\n        df['cumulative_volume'] = df['volume'].cumsum()\n        df['cumulative_price'] = df['cumulative_price_volume'].cumsum()\n        df['vwap'] = df['cumulative_price'] / df['cumulative_volume']\n        df = calculate_MACD(df)\n        df = calculate_RSI(df)\n        df= calculate_heikin_ashi(df)\n        df=atr(df)\n        df=aroon(df,14)\n        df = calculate_ichimoku(df)\n        df = add_total_signal(df)\n        dataframes[i] = df               # Update the dataframe in the list\n\n        # print(df.cloumns)\n\n    print(sum([frame[\"signals\"].value_counts() for frame in dataframes], start=0))\n    plot_ichimoku(df)\n    return dataframes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Back Testing Code :**","metadata":{}},{"cell_type":"code","source":"def create_file(dataframes, csv_file_name):\n    dataframes[0].to_csv(csv_file_name,index=True)\n    return \"./\"+csv_file_name","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def perform_backtest(csv_file_path):\n     client = Client()\n     result = client.backtest(\n        jupyter_id=\"test\",\n        file_path=csv_file_path,\n        leverage=1,\n     )\n     return result\n\n\ndef perform_backtest_large_csv(csv_file_path):\n    client = Client()\n    file_id = str(uuid.uuid4())\n    chunk_size = 90 * 1024 * 1024  # 90 MB\n    total_size = os.path.getsize(csv_file_path)\n    total_chunks = (total_size + chunk_size - 1) // chunk_size\n    chunk_number = 0\n\n    # Handle small files\n    if total_size <= chunk_size:\n        total_chunks = 1\n        result = client.backtest(\n            file_path=csv_file_path,\n            leverage=1,\n            jupyter_id=\"test\",\n        )\n        for value in result:\n            print(value)\n        return result\n\n    # Process large files in chunks\n    with open(csv_file_path, \"rb\") as f:\n        while True:\n            chunk_data = f.read(chunk_size)\n            if not chunk_data:\n                break\n\n            # Save each chunk temporarily in /tmp\n            chunk_file_path = f\"/tmp/{file_id}_chunk{chunk_number}.csv\"\n            with open(chunk_file_path, \"wb\") as chunk_file:\n                chunk_file.write(chunk_data)\n\n            # Perform backtest on the current chunk\n            result = client.backtest(\n                file_path=chunk_file_path,\n                leverage=1,\n                jupyter_id=\"test\",\n                file_id=file_id,\n                chunk_number=chunk_number,\n                total_chunks=total_chunks,\n            )\n\n            # Process the results of the backtest\n            for value in result:\n                print(value)\n\n            # Remove the temporary chunk file\n            os.remove(chunk_file_path)\n\n            # Move to the next chunk\n            chunk_number += 1\n\n    return result","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"folder_path = \"./\"\ncsv_file_name= 'dev.csv'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataframes = do_it(folder_path)\n\nprint(dataframes[0][\"signals\"].value_counts())\n\ncsv_file_path = create_file(dataframes, csv_file_name)\n\n#change to perform_backtest_large_csv(csv_file_path) for large files\nbacktest_result = perform_backtest_large_csv(csv_file_path)\nprint(backtest_result)\nfor value in backtest_result:\n    print(value)\n\nif os.path.exists(csv_file_path):\n    os.remove(csv_file_path)\n     \n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}